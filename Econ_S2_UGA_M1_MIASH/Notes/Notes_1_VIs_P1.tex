\documentclass[12pt, reqno]{amsart}
%\documentclass[12pt, reqno, fleqn]{amsart}
\input{header_fr}
%\raggedright \onehalfspacing \setlength{\parindent}{20pt} \allowdisplaybreaks
%\pagestyle{fancy} \lhead{\'Econométrie 1} \rhead{L3 MIASH, 2016-2017}
%\pagestyle{fancy} \rfoot{\textcopyright \ \  Michal W. Urdanivia}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[L]{\'Econométrie 2}
\fancyhead[R]{Master MIASH , 2016-2017}
\fancyfoot[R]{\textcopyright \ \  Michal W. Urdanivia}
\usepackage{authblk}
%\usepackage{sectsty}
\usepackage{lipsum}
\title{Endogénéité  et estimation par variables instrumentales}
\date{Année universitaire 2016-2017}
\begin{document}
\maketitle
\section{Introduction}
Dans ce notes nous commençons le traitement de la méthode des variables instrumentales(VIs par la suite)  pour corriger le problème de l'endogénéité des régresseurs dans le modèle de régression. 
\section{Endogénéité}
Considérons le modèle de régression partitionné suivant,
\begin{align}
Y_i &= X_i^\top\beta + U_i \nonumber\\
&= X_{i1}^\top\beta_1 + X_{i2}^\top\beta_2 + U_i 
\label{eq1}
\end{align}
où $X_{i1}$ est un vecteur $(K_1\times 1)$ et  $X_{i2}$ est un vecteur $(K_2\times 1)$, de régresseurs, $\beta_1$ est un vecteur $(K_1\times 1)$ et $\beta_2$ est un vecteur $(K_2\times 1)$ de paramètres inconnus, et $K_1 + K_2 = K$. Supposons que $X_{i1}$ est endogène,
\begin{align*}
\Er(X_{i1}U_i) \neq 0
\end{align*}
par opposition à $X_{i2}$ qui est (faiblement)exogène,
\begin{align*}
\Er(X_{i2}U_i) = 0
\end{align*}
(L'hypothèse $\Er(U_i| X_{i2}) = 0$ est appelée exogénéité forte). 
\subsection{Sources d'endogénéité}
\subsubsection*{Variables omises}
Considérons l'équation de salaire suivante,
\begin{align*}
\log Sal_i &= \alpha + \beta_1Etudes + \gamma Genre + \delta Abilité + V_i\\
&=\alpha + \beta_1Etudes + \gamma Genre + U_i
\end{align*}
\'Etant donné que $Abilité$ est inobservable elle se retrouve dans le terme d'erreur du modèle $U_i = \delta Abilité + V_i$. Nous pouvons considérer que la variable $Genre$ est exogène, mais $Abilité$ est vraisemblablement corrélée avec le niveau d'études , et par conséquent $Etudes$ est endogène.
\subsubsection*{\'Erreurs de mesure}
Supposons que le vrai modèle soit,
\begin{align*}
Y_i = \tilde{X}_{i1}^\top\beta + X_{i2}^\top\beta_2 + V_i
\end{align*}
où cependant $\tilde{X}_{i1}$ est inobservable. On observe à la place, $X_{i1} =  \tilde{X}_{i1}+\epsilon_i$ où $\epsilon$ est un vecteur de bruits indépendant de $\tilde{X}_{i1}$, et $X_{i2}$. Substituons $\tilde{X}_{i1}$ dans l'équation précédente,
\begin{align*}
Y_i = X_{i1} ^\top\beta + X_{i2}^\top\beta_2 - \epsilon_i^\top\beta + V_i
\end{align*}
Posons $U_i = - \epsilon_i^\top\beta + V_i$. Alors que $ X_{i2}$ est exogène, $X_{i1}$ est endogène car  corrélé avec $U_i$ par le biais de $\epsilon_i$.
\subsubsection*{Simultanéité}
Considérons l'équation suivante,
\begin{align*}
Heures_i = \beta_1Enfants_i + X_{i2}^\top\beta_2 + U_i
\end{align*}
où $Heures_i$ est le nombre d'heures travaillées par semaine, $Enfants_i$ est le nombre d'enfants dans une famille, et $X_{i2}$ est un vecteur de variables exogènes. Alors que le nombre d'enfant affecte l'offre de travail, il est raisonnable de penser que les décision de carrière affectent la taille de la famille, i.e., on doit considérer une autre équation qui détermine le nombre d'enfants dans la famille,
\begin{align*}
Enfants_i = \gamma Heures_i + Z_{i1}^\top\gamma_2+ + V_i
\end{align*}
où $ Z_{i1}$ est un autre vecteur de variables exogènes. En substituant l'expression pour les heures dans l'équation pour le nombre d'enfants, nous obtenons(en supposant que $1-\beta_1\gamma_1\neq 0$),
\begin{align*}
Enfants_i  = X_{i2}^\top\left(\frac{\beta_2\gamma_1}{1-\beta_1\gamma_1}\right) + Z_{i1}^\top \left(\frac{\gamma_2}{1-\beta_1\gamma_1}\right) + \left(\frac{\gamma_1}{1-\beta_1\gamma_1}\right)U_i + \left(\frac{1}{1-\beta_1\gamma_1}\right)V_i
\end{align*}
En supposant que $X_{i2}$, $Z_{i1}$, $V_i$ ne sont pas corrélés avec $U_i$, nous obtenons,
\begin{align*}
\Er(U_iEnfants_i) &= \left(\frac{\gamma_1}{1-\beta_1\gamma_1}\right)\Er(U_I^2)\\
&\neq 0
\end{align*}
\subsection{Propriétés de l'estimateur des moindres carrés en présence d'endogénéité}
Considérons l'estimateur des MCO de $\beta_1$ dans \eqref{eq1}. Pour cela considérons l'écriture matricielle du modèle,
\begin{align*}
\mathbf{Y} = \mathbf{X}_1\beta_1 + \mathbf{X}_2\beta_2 + \mathbf{U} 
\end{align*}
où $\mathbf{Y}$ est le vecteur $(n\times 1)$ ayant pour élément $i$ $Y_i$, $\mathbf{X}_1$ est la matrice $(n\times K_1)$ de régresseurs endogènes ayant pour ligne $i$ $X_{i1}^\top$, $\mathbf{X}_2$ est la matrice $(n\times K_2)$ de régresseurs exogènes ayant pour ligne $i$ $X_{i2}^\top$, et $\mathbf{U}$ est le vecteur $(n\times 1)$ ayant pour élément $i$ $U_i$. L'estimateur des MCO de $\beta_1$ est,
\begin{align*}
\widehat{\beta}_{1n} &= (\mathbf{X}_1^\top\mathbf{M}_2\mathbf{X}_1)^{-1}\mathbf{X}_1^\top\mathbf{M}_2\mathbf{Y} \\
&=\beta_1 +(\mathbf{X}_1^\top\mathbf{M}_2\mathbf{X}_1)^{-1}\mathbf{X}_1^\top\mathbf{M}_2\mathbf{U}
\end{align*}
où $\mathbf{M}_2 = \Id_n - \mathbf{X}_2(\mathbf{X}_2^\top\mathbf{X}_2)^{-1}\mathbf{X}_2^\top$. Nous avons,
\begin{align*}
n^{-1}\mathbf{X}_1^\top\mathbf{M}_2\mathbf{X}_1 &= n^{-1}\sumobs X_{i1}X_{i1}^\top - n^{-1}\sumobs X_{i1}X_{i2}^\top\left(n^{-1}\sumobs X_{i2}X_{i2}^\top\right)^{-1} n^{-1}\sumobs X_{i2}X_{i1}^\top\\
n^{-1}\mathbf{X}_1^\top\mathbf{M}_2\mathbf{U} &= n^{-1}\sumobs X_{i1}U_i - n^{-1}\sumobs X_{i1}X_{i2}^\top\left(n^{-1}\sumobs X_{i2}X_{i2}^\top\right)^{-1} n^{-1}\sumobs X_{i2}U_i^\top
\end{align*}

Supposons que,
\begin{itemize}
\item[$\bullet$] Les observations $\{(Y_i, X_i)\}_{i=1}^n$ sont i.i.d.
\item[$\bullet$] $\Er(X_{ik}^2) < \infty$ pour tout $k=1,...,K$.
\item[$\bullet$] $\Er(X_iX_i^\top)$ est définie positive.
\item[$\bullet$] $\Er(U_i^2) < \infty$.
\end{itemize}
Par la loi faible des grands nombre,
\begin{align*}
n^{-1}\sumobs X_{i1}X_{i1}^\top &\limp \Er(X_{i1}X_{i1}^\top)\\
n^{-1}\sumobs X_{i1}X_{i2}^\top &\limp \Er(X_{i1}X_{i2}^\top)\\
n^{-1}\sumobs X_{i2}X_{i2}^\top &\limp \Er(X_{i2}X_{i2}^\top)\\
n^{-1}\sumobs X_{i2}U_i^\top &\limp 0\\
n^{-1}\sumobs X_{i1}U_i^\top &\limp \Er(X_{i1}U_i)
\end{align*}
Ainsi,
\begin{align*}
n^{-1}\mathbf{X}_1^\top\mathbf{M}_2\mathbf{X}_1 &\limp \Er(X_{i1}X_{i1}^\top)-\Er(X_{i1}X_{i2}^\top)\left( \Er(X_{i2}X_{i2}^\top)\right)^{-1}\Er(X_{i2}X_{i1}^\top)\\
n^{-1}\mathbf{X}_1^\top\mathbf{M}_2\mathbf{U} &\limp \Er(X_{i1}U_i) - \Er(X_{i1}X_{i2}^\top)\left( \Er(X_{i2}X_{i2}^\top)\right)^{-1}\Er(X_{i2}U_i)\\
&=\Er(X_{i1}U_i) \\
&\neq 0
\end{align*}
et nous concluons que $\widehat{\beta}_{1n} $ n'est pas convergent,
\begin{align*}
\widehat{\beta}_{1n} &\limp \beta_1 + \left(\Er(X_{i1}X_{i1}^\top)-\Er(X_{i1}X_{i2}^\top)\left( \Er(X_{i2}X_{i2}^\top)\right)^{-1}\Er(X_{i2}X_{i1}^\top)\right)^{-1}\Er(X_{i1}U_i)\\
&\neq \beta_1
\end{align*}
La non convergence de l'estimateur des MCO de $\beta_2$ peut être montré de manière similaire. Nous avons,
\begin{align*}
\widehat{\beta}_{2n} = \beta_2 + (\mathbf{X}_2^\top\mathbf{M}_1\mathbf{X}_2)^{-1}\mathbf{X}_2^\top\mathbf{M}_1\mathbf{U}
\end{align*}
où $\mathbf{M}_1 = \Id_n - \mathbf{X}_1(\mathbf{X}_1^\top\mathbf{X}_1)^{-1}\mathbf{X}_1^\top$. Et nous avons,
\begin{align*}
\widehat{\beta}_{2n}  \limp \beta_2 + \left(\Er(X_{i2}X_{i2}^\top)-\Er(X_{i2}X_{i1}^\top)\left( \Er(X_{i1}X_{i1}^\top)\right)^{-1}\Er(X_{i1}X_{i2}^\top)\right)^{-1}\Er(X_{i2}X_{i1}^\top)\Er(X_{i1}X_{i1}^\top)^{-1}\Er(X_{i1}U_i)
\end{align*}
\section{Estimation par variables instrumentales}
Soit $Z_{i1}$ un vecteur $(K_1\times 1)$ de variables exogènes,
\begin{align*}
\Er(Z_{i1}U_i) = 0
\end{align*}
Il est important de noter que  $Z_{i1}$ est exclu du modèle \eqref{eq1}, i.e., $Z_{i1}$ ne contient aucun des éléments de $X_{i2}$. Définissons,
\begin{align*}
X_i =&\left(
\begin{array}{c}
X_{i1}\\
X_{i2}
\end{array}
\right),
\\
Z_i =&\left(
\begin{array}{c}
Z_{i1}\\
X_{i2}
\end{array}
\right)
\end{align*}
Ici, $X_i$ est le vecteur $(K\times 1)$ de régresseurs, et $Z_i$ est le vecteur $(K\times 1)$ de \emph{variables instrumentales}(VIs). Notons que les régresseurs exogènes apparaissent aussi dans les vecteur des VIs, et que pour chaque variables endogène nous avons une variables exogène(une VI) qui est exclue du modèle $Y_i = X_i^\top\beta +U_i$. Lorsque tous les régresseurs sont endogènes nous n'avons plus aucun élément commun à $X_i$ et à $Z_i$. \\
Nous supposons que les VIs sont informatives par rapport aux régresseurs. Ceci est exprimé par la \emph{condition de rang} suivante,
\begin{align}
\Rang\left(\Er(Z_iX_i^\top)\right) = K
\label{eq2}
\end{align}
La condition dans \eqref{eq2} échouera si, par exemple, $\Er(Z_{i1}X_i^\top) = 0$($Z_{i1}$ est exogène mais c'est un bruit aléatoire). La condition de rang échouera aussi si certains éléments de $Z_{i1}$ sont des combinaisons linéaires des éléments dans les régresseurs exogènes inclus $X_{i2}$.
\begin{exemple}
Reprenons le cas "Heures/Enfants". Angrist et Evans(1998) on suggéré d'utiliser la composition en termes de sexe des deux premier enfants  comme instrument pour le nombre d'enfants dans une famille(l'échantillon utilisé est restreint  aux femmes avec au moins deux enfants). Ceci est motivé par l'idée que si les deux premiers enfants sont du même sexe(fille-fille, ou garçon-garçon) la famille sera plus encline à avoir un troisième enfant que dans le cas où les deux premiers enfants sont de sexe différent. En conséquence, la variable indicatrice d'avoir deux premiers enfants du même sexe doit être positivement corrélée avec le nombre d'enfants. D'un autre côté , l'instrument est exogène car la composition en termes de sexe des deux premiers enfants est déterminée aléatoirement.
\end{exemple}
Nous avons,
\begin{align*}
\Er(Z_iU_i) = 0
\end{align*}
L'application de la méthode des moments suggère un estimateur solution du système suivant de $K$ équations,
\begin{align*}
n^{-1}\sumobs Z_I\left(Y_i-X_i^\top\widehat{\beta}_n^{VI}\right) = 0
\end{align*}
d'où,
\begin{align*}
\widehat{\beta}_n^{VI} &= \left(\sumobs Z_iX_i^\top\right)^{-1}\sumobs Z_iY_i\\
&=(\mathbf{Z}^\top\mathbf{X})^{-1}\mathbf{Z}^\top\mathbf{Y}
\end{align*}
où $\mathbf{X}$ est la matrice $(n\times K)$ ayant pour élément $i$ $X_i^\top$, et $\mathbf{Z}$ est la matrice $(n\times K)$ ayant pour élément $i$ $Z_i^\top$.\\
L'estimateur $\widehat{\beta}_n^{VI}$ est appelé \emph{estimateur des variables instrumentales} de $\beta$.
Nous étudions maintenant sa convergence, et sa normalité asymptotique. Pour cela nous supposons que,
\begin{itemize}
\item[$\bullet$] Les observations $\{(Y_i, X_i, Z_i)\}_{i=1}^n$ sont i.i.d.
\item[$\bullet$] $\Er(Z_iU_i) = 0$ pour tout $k=1,...,K$.
\item[$\bullet$] $\Er(X_{ik}^2) < \infty$ pour tout $k=1,...,K$.
\item[$\bullet$] $\Er(Z_{i1k}^2) < \infty$ pour tout $k=1,...,K_1$.
\item[$\bullet$] $\Er(Z_iX_i^\top)$ est de rang $K$.
\item[$\bullet$] $\Er(U_i^2Z_iZ_i^\top)$ est définie positive.
\end{itemize}
\'Ecrivons,
\begin{align}
\widehat{\beta}_n^{VI} = \beta + \left(n^{-1}\sumobs Z_iX_i^\top\right)^{-1}n^{-1}\sumobs Z_iU_i
\label{eq3}
\end{align}
Notons que sous les hypothèses faites plus haut, par l'inégalité de Cauchy-Schwartz,
\begin{align*}
\Er(\abs{Z_{ir}X_{is}}) &\leq \sqrt{\Er(Z_{ir}^2)\Er(X_{is}^2)}\\
&< \infty \ \textrm{pour tout} \ r, s = 1,...,K.
\end{align*}
Par conséquent, par le théorème de Slutsky,
\begin{align*}
\widehat{\beta}_n^{VI}  &\limp \beta + \Er(Z_iX_i^\top)^{-1}\Er(Z_iU_i)\\
&= \beta
\end{align*}
Afin de montrer la normalité asymptotique nous supposons en outre que,
\begin{itemize}
\item[$\bullet$] $\Er(Z_{ik}^4) < \infty$, pour tout $k=1,...,K$. 
\item[$\bullet$] $\Er(U_i^4)<\infty$.
\end{itemize}
\'Ecrivons \eqref{eq3} comme suit,
\begin{align*}
n^{1/2}(\widehat{\beta}_n^{VI} - \beta ) = \left(n^{-1}\sumobs Z_iX_i^\top\right)^{-1}n^{-1/2} \sumobs Z_iU_i
\end{align*}
Notons que du fait des hypothèses précédentes,
\begin{align*}
\Er(\abs{U_i^2Z_{ir}Z_{is}}) &\leq (\Er(U_i^4))^{1/2}\Er(Z_{ir}^4Z_{is}^4)^{1/4}\\
& < \infty
\end{align*}
Par conséquent, par le théorème central-limite et le théorème de convergence de Cramer,
\begin{align*}
n^{1/2}(\widehat{\beta}_n^{VI} - \beta ) &\limd (\Er(Z_iX_i^\top))^{-1}\mathcal{N}\left(0,\Er(U_i^2Z_iZ_i^\top)\right)\\
&=\mathcal{N}\left(0,  (\Er(Z_iX_i^\top))^{-1}\Er(U_i^2Z_iZ_i^\top) (\Er(X_iZ_i^\top))^{-1}\right)
\end{align*}
La matrice de variances-covariances asymptotique prend une forme en sandwich et peut être estimé de manière convergente par,
\begin{align*}
\left(n^{-1}\sumobs Z_iX_i^\top\right)^{-1} n^{-1} \sumobs (\widehat{U}_i^2Z_iZ_i^\top) \left(n^{-1}\sumobs X_iZ_i^\top\right)^{-1}
\end{align*}
où $\widehat{U}_i = Y_i - X_i^\top\widehat{\beta}_n^{VI}$.

%\bibliographystyle{plainnat}
%\bibliography{../Biblio}
\end{document}