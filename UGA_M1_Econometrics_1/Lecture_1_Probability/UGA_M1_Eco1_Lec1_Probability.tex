
\input{../UGA_M1_Eco1_config_slides}

\title[Econometrics 1: Introduction]{UGA M1: Econometrics 1\\ \textbf{Probability}}
\date{\today}
\author{Michal W. Urdanivia\inst{*}}
\institute{\inst{*}Universit\'e de Grenoble Alpes, Facult\'e d'\'Economie, GAEL, \\e-mail: \href{mailto:michal.wong-urdanivia@univ-grenoble-alpes.fr}{michal.wong-urdanivia@univ-grenoble-alpes.fr}}


\begin{document}

\frame{\titlepage}
%\setcounter{tocdepth}{2}

\begin{frame}
  \tableofcontents  
\end{frame}

\begin{frame}\frametitle{References}
  \begin{itemize}
  \item \cite{w2013} appendix B
  \item \cite{sw2009} chapter 2
  \item \cite{abbring2001} sections 2.1-2.3
  \item \cite{dbc2012} chapter 2 
  \item \cite{gs2003} chapters 1-7
  \end{itemize}

\begin{itemize}
\item These lectures are mostly based on Wooldridge, so that will
generally be the best reference to read. 
\item The others are some
freely available alternatives that cover similar
material. 
\item \cite{abbring2001} is most similar to Wooldridge in
terms of length and its focus on econometrics. 
\item \cite{dbc2012} and
\cite{gs2003} also cover similar material, but explain things in
more depth.
\end{itemize}
\end{frame}

\begin{frame}[allowframebreaks] \frametitle{Probability}
  \begin{itemize}
  \item Purpose: system for quantifying chance and making predictions
    about future events 
  \item Interpretations:
    \begin{itemize}
    \item Relative frequency of an event in many repeated trials
    \item Subjective assessment of the likelihood of an event
    \end{itemize}
  \end{itemize}
\end{frame}

\section{Definitions}

\begin{frame}[allowframebreaks]\frametitle{Basic definitions}
\begin{itemize}
\item The properties of probability are fairly intuitive, and you can
work with probabilities without worrying too much about how
probability is formally defined. 
\item However, if we want to be
mathematically rigorous, we should carefully define what we mean
by probability. 
\item This slide formally defines probability. Do not
worry if it seems very abstract.
\framebreak
\item \alert{Random experiment}: procedure that has well-defined set
    of outcomes and ``could'' be infinitely repeated
  \item \alert{Sample space}: set of possible outcomes of an
    experiment, $S = \{a_1,
    a_2, ..., a_J\}$
  \item \alert{Event}: any subset of sample space, $A \subseteq S$ 
  \item \alert{Probability}: function from all subsets of the sample
    space, $S$, to $[0,1]$
    such that
    \begin{enumerate}
    \item\label{pa1} $\Pr(S) = 1$
    \item\label{pa2} $1 \geq \Pr(A) \geq 0$ for all $A \subseteq S$
    \item\label{pa3} If $A_1, A_2,. . .$ are disjoint events then $ \Pr(A_1 \cup
      A_2 \cup ...) = \Pr (A_1) + \Pr (A_2) + . . .$
    \end{enumerate}
  \item \alert{Random variable}: function from $S$ to a number 
  
\framebreak
\item An example of a random experiment is rolling a dice. In this case the
sample space is $S=\{1,2,3,4,5,6\}$. 

\item Some events are: get a $1 =
\{1\}$, get more than 4, $\{5, 6\}$, etc.

\item A random variable is a numeric representation of a random
experiment. 

\item For example, our experiment could be flipping a coin. Then
$S = \{\mathrm{heads},\mathrm{tails}\}$. 

\item A function assigns a number
to each element of $S$, so one example of a
random variable is $X = \begin{cases} 1 & \text{ if heads} \\
  0 & \text{ if tails} \end{cases}$. 

\item Another is
$Y = \begin{cases} 50 & \text{ if heads} \\
  -257 & \text{ if tails} \end{cases}$. 

\item A third example is
$Z = \begin{cases} 1 & \text{ if heads} \\
  1 & \text{ if tails} \end{cases}$.
\end{itemize}
\end{frame}

\begin{mdframed}[frametitle={Sets}]
Sets appear throughout mathematics. A \textbf{set} is any well-defined
collection of objects. We will usually denote sets by capital
letters. The things in a set are generally called \textbf{elements} of
the set. For a sample space, the elements are the possible outcomes of
an experiment. There is some notation related to sets that is
useful. We list the elements of set inside braces, so for example the
set of the colors red and green, could be written as
$\{\mathrm{red},\mathrm{green}\}$.

We can combine two sets to create a new one by taking the union or
intersection of the sets. The \textbf{union} of set $A$ and set $B$ is
written $A \cup B$ and is the set of everything in either $A$ or $B$
or both. The \textbf{intersection} of set $A$ and $B$ is written $A
\cap B$ and is the set of everything in both $A$ and $B$.  Two sets
are \textbf{disjoint} if their intersection is empty.

The set with nothing in it is called the \textbf{empty set} and is
denoted by $\emptyset$.
      
If every element of $A$ is also an element of $B$, then we say that
$A$ is a subset of $B$ and denote this by $A \subseteq B$. If there is
also something in $B$ that is not in $A$ (i.e. $A$ and $B$ are not the
same), then we say that $A$ is a strict subset of $B$ and write it as
$A \subset B$.
\end{mdframed}


\section{Properties}
    
From the definition of probability on the previous slide, we can
derive some intuitive properties. Each of these properties are fairly
obvious. The point of showing that they follow from the previous
definition is to verify that the formal definition agrees with our
informal idea of probability. If they didn't agree, it would tell us
that there is something wrong with our formal definition.

\begin{frame}[allowframebreaks]\frametitle{Properties of probability}
  \begin{enumerate}
  \item $\Pr(\emptyset) = 0$ 
    \note{This is more a convention implied by the axioms than a
      meaningful statement. Derivation: $S$ and $\emptyset$ are disjoint,
      so $\Pr(S \cup \emptyset) = \Pr(S) + \Pr(\emptyset) = 1 +
      \Pr(\emptyset)$. Also, $S \cup \emptyset = S$, so $\Pr(S \cup \emptyset) =
      \Pr(S) = 1$. Combining, $1 = 1 + \Pr(\emptyset)$, so $\Pr(\emptyset) =
      0$}
  \item $\Pr(A^c ) = 1 - \Pr(A)$
    \note{$A^c \cup A = S$, $A^c$ and $A$ are disjoint, so \ref{pa1}
      and \ref{pa3} imply this property.}
  \item $A \subseteq B$ implies $\Pr(A) \leq \Pr(B)$
    \note{$A \subseteq B$ implies $B = (B \setminus A) \cup A$. $B
      \setminus A)$ and $A$ are disjoint. \ref{pa2} and \ref{pa3} give
      this conclusion.}
  \item $\Pr(A \cup B) = \Pr(A) + \Pr(B) - \Pr(A \cap B)$ 
    \note{$A \cap B$ is read ``the intersection of $A$ and $B$'' or
      ``$A$ and $B$.'' It is the event that both $A$ and $B$
      occur. Proof of this property is similar to previous.}
  \end{enumerate}
\end{frame}

Conditional probability is very important for making decisions and
interpreting our observations of the world. Often, we would like to
know about something that we do not directly observe, but we do
observe some related information. For example, to forecast GDP next
quarter, which is something we can not observe today, we can use
current information about GDP, inflation, consumer confidence, etc. To
make a forecast, we do not care so much about the unconditional
probability that GDP tomorrow is high, but about the probability that
GDP tomorrow is high given what we observe today.

\begin{frame}[allowframebreaks]\frametitle{Conditional probability}
  \begin{itemize}
  \item \alert{Conditional probability}: $\Pr(A | B) = \Pr(A \cap B) /
    \Pr(B)$ 
    \begin{itemize}
    \item Satisfies axioms of unconditional probability (and so also
      has properties on previous slide)
    \end{itemize}
  \item\alert{Bayes' Rule} $\Pr(A | B ) = \frac{\Pr (B | A) \Pr(A) } {\Pr(B) }$ 
  \item $A$ is \alert{independent} of $B$ iff $\Pr(A \cap B) = \Pr(A) \Pr(B)$,
    denote as $A \indep B$
    \begin{itemize}
    \item $A \indep B$ implies $\Pr(A | B) = \Pr(A)$ and $\Pr(B | A) = 
      \Pr(B)$.
    \end{itemize}
  \end{itemize}    
\end{frame}
Proof of Bayes' rule: definition of conditional probability
$\Pr(A \cap B) = \Pr(A | B) \Pr(B)$, and switching role of $A$
and $B$, $= \Pr(B | A ) \Pr(A)$. Rearrange to get conclusion.

Bayes' Rule allows us to switch between the $\Pr(A|B)$ and
$\Pr(B |A)$. It is very useful. One common use is for
interpreting the results of screening tests. For example,
suppose there is a test for some disease. From clinical trials,
we would likely know the probability of correctly testing positive
conditional on having the disease, $\Pr(+|\mathrm{disease})$,
and the probability of falsely testing positive,
$\Pr(+|\mathrm{healthy})$. Suppose the unconditional probability
of having the disease if $\Pr(\mathrm{disease})$. From this, we
can use Bayes' rule to calculate the probability of having the
disease conditional on testing positive as:
\begin{align*}
  \Pr(\mathrm{disease}|+) = & \frac{\Pr(+|\mathrm{disease})
    \Pr(\mathrm{disease})} {\Pr(+)} \\
  = & \frac{\Pr(+|\mathrm{disease}) \Pr(\mathrm{disease})} 
  {\Pr(+|\mathrm{disease}) \Pr(\mathrm{disease}) +
    \Pr(+|\mathrm{healthy}) (1-\Pr(\mathrm{disease}))}.
\end{align*}

When $A$ and $B$ are independent, then knowing whether $B$ happens
does not give you any information about the probability of $A$
occurring.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Random variables}

\subsection{Discrete}

\begin{frame}
  \frametitle{Discrete random variables}
  \begin{itemize}
  \item Recall: a \alert{random variable} is a function from $S$ to a
    number 
  \item A random variable is \alert{discrete} if it can only take
    countably many different values 
  \item E.g.\ $X \in \{x_1, ..., x_m\}$
  \item \alert{Probability mass function (PMF)} of $X$, $p_i = \Pr(X
    = x_i)$ gives the probability that $X$ equals each of its possible
    values 
  \item \alert{Cumulative distribution function (CDF)}: $F(x) = \Pr(X
    \leq x) = \sum_{i=1}^m p_i 1\{x_i \leq x \}$    
  \end{itemize}
\end{frame}

\subsection{Continuous}
\begin{frame} 
  \frametitle{Continuous random variables}
  \begin{itemize}
  \item A random variable is \alert{continuous} if it takes on any
    single real value with zero probability 
  \item Set of possible values is uncountably infinite (e.g.\ real
    line or line segment)
  \item CDF is continuous and differentiable  
  \item \alert{Probability density function (PDF)}: the derivative of
    the CDF
    \[ f(x) = \frac{dF}{dx}(x) \;\text{ and }\; F(x) =
    \int_{-\infty}^x f(t) dt \]
  \end{itemize}
\end{frame}

\subsection{Bivariate distributions}

\begin{frame}
  \frametitle{Bivariate distributions}
  \begin{itemize}
  \item Discrete: 
    \begin{itemize}
    \item Joint PMF $f_{X,Y}(x,y) = \Pr(X = x, Y = y)$
    \item Marginal PMF $f_X(x) = \Pr(X = x) = \sum_{y \in \text{all values
          of } Y} \Pr(X=x,Y=y)$
    \item Conditional PMF $f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$
    \end{itemize}
  \item Continuous: 
    \begin{itemize}
    \item joint CDF $F_{X,Y}(x,y) = \Pr(X \leq x, Y \leq y) =
      \int_{-\infty}^x \int_{-\infty}^y f_{X,Y}(u,t) du dt$ 
    \item joint PDF $f_{X,Y}(x,y) = \frac{\partial^2 F_{X,Y}}{\partial
        x \partial y}(x,y)$
    \item Marginal CDF for $X$, $F_X(x) = \Pr(X \leq x) =
      F_{X,Y}(x,\infty)$
    \item Marginal PDF for $X$, $f_X(x) = \frac{d F_X}{dx}(x) =
      \int_{-\infty}^\infty f_{X,Y}(x,y) dy$
    \item Conditional PDF $f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$
    \end{itemize}    
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Independence}
  \begin{itemize}
  \item Random variables $X,Y$ are independent if $f_{X,Y}(x,y) =
    f_X(x) f_Y(y)$ for all $x,y$
    \note{$f$ is either PMF or PDF depending on whether random
      variables are discrete or continuous.}
  \item $X \indep Y$ implies $f_{X|Y}(x|y) = f_X(x)$
  \end{itemize}
\end{frame}

\subsection{Expectations}

We will use expectations a lot, so it's important to understand them
and know their properties. The fact that the expectation is linear and
the law of iterated expectations will be especially useful.  

\begin{frame}\frametitle{Expectation}
  \begin{itemize}
  \item The \alert{expectation} of $X$ is
    \[ 
    \Er[X] = \begin{cases} \sum_{i=1}^m x_i f_X(x_i) & \text{ if $X$
        discrete}  \\
      \int_{-\infty}^\infty x f_X(x) dx & \text{ if $X$
        continuous}
    \end{cases}
    \]  
    \begin{itemize}
    \item Is a constant
    \item a.k.a. expected value, population average, population mean,
      first moment
    \end{itemize}
  \item Expectation is linear:
    \[ \Er[a X + b Y] = a \Er[X] + b \Er[Y] \]
  \item Expectation of function $g$:
    \[ \Er[g(X) ] = \int_{-\infty}^\infty g(x) f_X(x) dx \]
  \end{itemize}
\end{frame}

\begin{frame} \frametitle{Variance and other moments}
  \begin{itemize}
  \item \alert{$k$th moment} of $X$: $\Er[X^k]$
  \item \alert{$k$th central moment} of $X$: $\Er\left[\left(X -
        \Er[X]\right)^k\right]$ 
  \item \alert{Variance} is the 2nd central moment
    \begin{align*}
      \Var(X) = & \Er\left[ \left(X - \Er[X]\right)^2 \right] \\
      = & \Er[X^2] - \Er[X]^2
    \end{align*}
  \item $\Var(a + b X) = b^2 \Var(X)$
  \item \alert{Standard deviation} is $\sqrt{\Var(X)}$
  \end{itemize}
\end{frame}

\begin{frame} \frametitle{Covariance}
  \begin{itemize}
  \item \alert{Covariance} of $X$ and $Y$: 
    \begin{align*} 
      \Cov(X,Y) = & \Er\left[
        \left(X - \Er[X] \right) \left(Y - \Er[Y] \right) \right] \\ 
      = & \Er[X Y] - \Er[X] \Er[Y] \\
      = & \Er[\left(X - \Er[X]\right)Y] = \Er[X\left(Y - \Er[Y]\right)] 
    \end{align*}
  \item $\Cov(X,X) = \Var(X)$
  \item $\Cov(a_1 + b_1 X + c_1 Y, a_2 + b_2 X + c_2 Y) = b_1 b_2
    \Var(X) + c_1 c_2 \Var(Y) + (b_1 c_2 + c_1 b_2 ) \Cov(X, Y)$
  \item $\Var(a + bX + cY) =  b^2 \Var(X) + c^2\Var(Y) + 2bc
    \Cov(X,Y)$
  \item $\Var\left(\sum_{i=1}^N b_i X_i \right) = \sum_{i=1}^N
    \left(\sum_{j=1}^N b_i b_j \Cov(X_i,X_j) \right)$
  \end{itemize}
\end{frame}

We will often need to calculate the variance of sums like in the last two
bullet points. You should make sure you're comfortable with them. It's
not too much algebra to derive them from the definition of
variance. Let's do so now. 
\begin{align*}
  \Var(a + bX + cY) = & \Er\left[(a+bX+cY - \Er[a + bX + cY])^2\right]
  && \text{definition of variance} \\
  = & \Er\left[\left(a+bX+cY - (a + b\Er[X] + c\Er[Y])\right)^2 \right]
  && \text{linearity of expectation} \\
  = & \Er\left[ \left( b (X - \Er[X]) + c(Y - \Er[Y]) \right)^2\right]
  && \text{rearranging terms} \\
  = & \Er\left[ b^2 (X - \Er[X])^2 + c^2(Y - \Er[Y])^2 +
      2bc(X-\Er[X])(Y-\Er[Y]) \right] && \text{expanding the square}
  \\ 
  = & b^2 \Er[(X- \Er[X])^2] + c^2 \Er[(Y - \Er[Y])^2] + 2bc
      \Er\left[(X-\Er[X])(Y-\Er[Y]) \right] 
  && \text{linearity of expectation} \\
  = & b^2 \Var(X) + c^2 \Var(Y) + 2bc \Cov(X,Y) 
  && \text{defination of variance}
\end{align*}
The last bullet with the summation follows from similar logic. 


\begin{frame}
  \frametitle{Correlation}
  \begin{itemize}
  \item \alert{Correlation} of $X$ and $Y$ is
    $\corr(X,Y) = \frac{\Cov(X,Y)}{\sqrt{\Var(X) \Var(Y)}}$
  \item \alert{Cauchy-Schwartz inequality}: $\abs{\Cov(X,Y)} \leq
    \sqrt{\Var(X) \Var(Y)}$
    \begin{itemize}
    \item Implies $-1 \leq \corr(X,Y) \leq 1$
    \end{itemize}
  \item $\corr(X,Y) = \pm 1$ iff $Y = a + b X$ 
  \end{itemize}
\end{frame}

\subsection{Conditional expectation}

\begin{frame} \frametitle{Conditional expectation}
  \begin{itemize}
  \item \alert{Conditional expectation} of $Y$ given $X=x$:
    \[ \Er[Y | X = x ] = \begin{cases} \sum_{i=1}^m y_i f_{Y|X}(y_i|x) & \text{ if
        discrete}  \\
      \int_{-\infty}^\infty y f_{Y|X}(y|x) dy & \text{ if 
        continuous}
    \end{cases}
    \]
  \item $\Er[Y | X]$ is a function of $X$
  \item Has all properties of unconditional expectation
  \item Properties:
    \begin{itemize}
    \item $\Er[ g_1(X) + g_2(X) Y | X] = g_1(X) + g_2(X) \Er[Y | X]$
    \item \alert{Law of iterated expectations}: $\Er_X \left[
        \Er_{Y|X}[Y|X] \right] = \Er[Y]$
    \item $\Er\left[X \left(Y - \Er[Y|X] \right) \right] = 0$
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame} \frametitle{Conditional variance}
  \begin{itemize}
  \item \alert{Conditional variance}: $\Var(Y|X)= \Er\left[ \left(Y -
        \Er[Y|X] \right)^2 | X \right]$
  \item Relation to variance:
    \begin{align*}
      \Var(Y) = \Er_X\left[ \Var(Y|X)  \right] + \Var\left( \Er[Y | X]
      \right)
    \end{align*}
    \begin{itemize}
    \item Analysis of variance (ANOVA)
    \item $\Er_X\left[ \Var(Y|X)  \right]$ is within-$X$ variance
    \item $\Var\left( \Er[Y|X]  \right)$ is between-$X$ variance
    \end{itemize}
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[allowframebreaks]
  \frametitle{References}
 \bibliographystyle{jpe}
\bibliography{../UGA_M1_Eco1_biblio}
\end{frame}


\end{document}